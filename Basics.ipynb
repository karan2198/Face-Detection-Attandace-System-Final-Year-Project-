{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0295ade0-bffd-4d55-b3d5-8841b2a7c22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cmake in ./env/lib/python3.12/site-packages (3.30.5)\n",
      "Requirement already satisfied: dlib in ./env/lib/python3.12/site-packages (19.24.6)\n",
      "Requirement already satisfied: opencv-python in ./env/lib/python3.12/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy in ./env/lib/python3.12/site-packages (2.1.2)\n",
      "Requirement already satisfied: face-recognition in ./env/lib/python3.12/site-packages (1.3.0)\n",
      "Requirement already satisfied: matplotlib in ./env/lib/python3.12/site-packages (3.9.2)\n",
      "Requirement already satisfied: pillow in ./env/lib/python3.12/site-packages (11.0.0)\n",
      "Requirement already satisfied: face-recognition-models>=0.3.0 in ./env/lib/python3.12/site-packages (from face-recognition) (0.3.0)\n",
      "Requirement already satisfied: Click>=6.0 in ./env/lib/python3.12/site-packages (from face-recognition) (8.1.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./env/lib/python3.12/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./env/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./env/lib/python3.12/site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./env/lib/python3.12/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in ./env/lib/python3.12/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./env/lib/python3.12/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./env/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./env/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install cmake dlib opencv-python numpy face-recognition matplotlib pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9cc84dd1-321a-46bd-952e-2ad6e2f117e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Karan/IMG-20241018-WA0022.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Karan/IMG-20241018-WA0023.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Karan/karan.jpeg.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Karan/IMG-20241018-WA0021.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Karan/IMG-20241018-WA0024.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Karan/WhatsApp Image 2024-10-18 at 11.20.57_f8a09022.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Karan/IMG-20241018-WA0019.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Bhavyasri/IMG_20241028_221201.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Bhavyasri/Snapchat-793809341.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Bhavyasri/IMG_20241028_212627.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Bhavyasri/1730133938782_yfp2ux_2_0.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Bhavyasri/IMG-20230218-WA0020.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Bhavyasri/IMG_20240727_182913.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Bhavyasri/IMG_20241029_013600.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Bhavyasri/IMG_20241028_223925.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Bhavyasri/IMG-20241029-WA0002.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Bhavyasri/IMG_20240203_152009.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Bhavyasri/IMG_20241028_213013.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Bhavyasri/Polish_20241029_013429050.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Bhavyasri/IMG_20241028_220946.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Bhavyasri/IMG_20241028_212832.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Bhavyasri/IMG_20241029_021807.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Harsh/IMG-20241029-WA0049.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Harsh/.DS_Store\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Harsh/IMG-20241029-WA0051.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Harsh/IMG-20241029-WA0050.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Harsh/IMG-20241029-WA0052.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Harsh/IMG-20241029-WA0053.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Anand/.DS_Store\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Anand/WhatsApp Image 2024-10-29 at 18.37.31.jpeg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Anand/WhatsApp Image 2024-10-29 at 18.37.30.jpeg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Anand/WhatsApp Image 2024-10-29 at 18.37.29 (1).jpeg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Anand/Anand4.png\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Anand/Anand10.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Anand/WhatsApp Image 2024-10-29 at 18.37.29.jpeg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Anand/Anand7.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Anand/Anand3.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Anand/WhatsApp Image 2024-10-29 at 18.37.28.jpeg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Anand/Anand2.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Anand/Anand1.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Anand/WhatsApp Image 2024-10-29 at 18.37.29 (2).jpeg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Anand/Anand1.jpeg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Gaurav/.DS_Store\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Gaurav/IMG-20241029-WA0014.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Gaurav/IMG-20241029-WA0016.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Gaurav/IMG-20241029-WA0003.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Gaurav/IMG-20241029-WA0007.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Gaurav/IMG-20241029-WA0006.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Gaurav/IMG-20241029-WA0012.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Gaurav/IMG-20241029-WA0010.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Gaurav/IMG-20241029-WA0011.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Gaurav/IMG-20241029-WA0005.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Gaurav/IMG-20241029-WA0009.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Gaurav/IMG-20241029-WA0018.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Mythili/.DS_Store\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Mythili/IMG-20240318-WA0043.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Mythili/IMG-20241029-WA0032.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Mythili/IMG-20241029-WA0033.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Mythili/IMG-20241029-WA0031.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def detect_and_crop_faces(input_folder, output_folder):\n",
    "    # Load OpenCV's Haar Cascade for face detection\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    # Create output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Iterate over all subfolders in the input folder\n",
    "    for person_folder in os.listdir(input_folder):\n",
    "        person_input_path = os.path.join(input_folder, person_folder)\n",
    "\n",
    "        # Check if it's a directory (skip files)\n",
    "        if os.path.isdir(person_input_path):\n",
    "            person_output_path = os.path.join(output_folder, person_folder)\n",
    "\n",
    "            if not os.path.exists(person_output_path):\n",
    "                os.makedirs(person_output_path)\n",
    "\n",
    "            # Process all images in each person's folder\n",
    "            for filename in os.listdir(person_input_path):\n",
    "                image_path = os.path.join(person_input_path, filename)\n",
    "                img = cv2.imread(image_path)\n",
    "\n",
    "                print(f\"Image being Cropped: {image_path}\")\n",
    "                \n",
    "                # Check if image is read successfully\n",
    "                if img is not None:\n",
    "                    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                    \n",
    "                    # Detect faces in the image\n",
    "                    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "                    \n",
    "                    # Crop and save each detected face\n",
    "                    for (x, y, w, h) in faces:\n",
    "                        face_img = img[y:y+h, x:x+w]\n",
    "                        face_filename = os.path.join(person_output_path, filename)\n",
    "                        cv2.imwrite(face_filename, face_img)\n",
    "\n",
    "# Example usage for detecting and cropping faces from multiple folders\n",
    "input_folder = '/Users/narendraraj/fr/final_dataset/dataset'\n",
    "output_folder = '/Users/narendraraj/fr/final_dataset/cropped_faces'\n",
    "\n",
    "detect_and_crop_faces(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c0c058c-6202-42b9-8193-07be1873a9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Karan/IMG-20241018-WA0022.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Karan/IMG-20241018-WA0023.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Karan/karan.jpeg.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Karan/IMG-20241018-WA0021.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Karan/WhatsApp Image 2024-10-18 at 11.20.57_f8a09022.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Karan/IMG-20241018-WA0019.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Bhavyasri/IMG_20241028_221201.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Bhavyasri/Snapchat-793809341.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Bhavyasri/.DS_Store\n",
      "Skipping file: /Users/narendraraj/fr/final_dataset/cropped_faces/Bhavyasri/.DS_Store, not a valid image\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Bhavyasri/IMG_20241028_212627.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Bhavyasri/1730133938782_yfp2ux_2_0.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Bhavyasri/IMG-20230218-WA0020.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Bhavyasri/IMG_20240727_182913.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Bhavyasri/IMG_20241029_013600.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Bhavyasri/IMG_20241028_223925.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Bhavyasri/IMG-20241029-WA0002.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Bhavyasri/IMG_20240203_152009.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Bhavyasri/IMG_20241028_213013.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Bhavyasri/IMG_20241029_021807.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Harsh/IMG-20241029-WA0049.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Harsh/IMG-20241029-WA0051.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Harsh/IMG-20241029-WA0050.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Harsh/IMG-20241029-WA0052.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Harsh/IMG-20241029-WA0053.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Anand/WhatsApp Image 2024-10-29 at 18.37.31.jpeg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Anand/WhatsApp Image 2024-10-29 at 18.37.30.jpeg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Anand/WhatsApp Image 2024-10-29 at 18.37.29 (1).jpeg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Anand/Anand4.png\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Anand/Anand10.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Anand/WhatsApp Image 2024-10-29 at 18.37.29.jpeg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Anand/Anand7.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Anand/Anand3.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Anand/WhatsApp Image 2024-10-29 at 18.37.28.jpeg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Anand/Anand2.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Anand/Anand1.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Anand/WhatsApp Image 2024-10-29 at 18.37.29 (2).jpeg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Anand/Anand1.jpeg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Gaurav/.DS_Store\n",
      "Skipping file: /Users/narendraraj/fr/final_dataset/cropped_faces/Gaurav/.DS_Store, not a valid image\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Gaurav/IMG-20241029-WA0014.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Gaurav/IMG-20241029-WA0016.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Gaurav/IMG-20241029-WA0003.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Gaurav/IMG-20241029-WA0007.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Gaurav/IMG-20241029-WA0012.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Gaurav/IMG-20241029-WA0011.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Gaurav/IMG-20241029-WA0005.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Gaurav/IMG-20241029-WA0009.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Mythili/IMG-20240318-WA0043.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Mythili/IMG-20241029-WA0032.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Mythili/IMG-20241029-WA0033.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Mythili/IMG-20241029-WA0031.jpg\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def resize_images(input_folder, output_folder, size=(224, 224)):\n",
    "    # Create output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # Iterate over each subfolder (person's folder) in the input folder\n",
    "    for person_folder in os.listdir(input_folder):\n",
    "        person_input_path = os.path.join(input_folder, person_folder)\n",
    "        person_output_path = os.path.join(output_folder, person_folder)\n",
    "\n",
    "        # Check if it's a directory (skip files)\n",
    "        if os.path.isdir(person_input_path):\n",
    "            if not os.path.exists(person_output_path):\n",
    "                os.makedirs(person_output_path)\n",
    "\n",
    "            # Process each image in the person's folder\n",
    "            for filename in os.listdir(person_input_path):\n",
    "                image_path = os.path.join(person_input_path, filename)\n",
    "\n",
    "                print(f\"Resizing Image: {image_path}\")\n",
    "\n",
    "                # Try to open the image, skip if it's not an image file\n",
    "                try:\n",
    "                    img = Image.open(image_path)\n",
    "                    img_resized = img.resize(size)\n",
    "                    img_resized.save(os.path.join(person_output_path, filename))\n",
    "                except (IOError, OSError):\n",
    "                    print(f\"Skipping file: {image_path}, not a valid image\")\n",
    "\n",
    "# Example usage to resize images in multiple subfolders\n",
    "input_folder = '/Users/narendraraj/fr/final_dataset/cropped_faces'\n",
    "output_folder = '/Users/narendraraj/fr/final_dataset/resized_faces'\n",
    "\n",
    "resize_images(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8eda103c-8acd-4e44-b7e3-855e79e4e602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The lines `import cv2`, `import numpy as np`, and `import face_recognition` are importing necessary\n",
    "# libraries in Python for image processing and face recognition tasks.\n",
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import os\n",
    "import pickle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d865cf8c-e8ca-4050-b735-257a03451468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image files: ['/Users/narendraraj/fr/final_dataset/resized_faces/Karan/IMG-20241018-WA0022.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Karan/IMG-20241018-WA0023.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Karan/karan.jpeg.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Karan/IMG-20241018-WA0021.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Karan/WhatsApp Image 2024-10-18 at 11.20.57_f8a09022.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Karan/IMG-20241018-WA0019.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Bhavyasri/IMG_20241028_221201.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Bhavyasri/Snapchat-793809341.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Bhavyasri/IMG_20241028_212627.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Bhavyasri/1730133938782_yfp2ux_2_0.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Bhavyasri/IMG-20230218-WA0020.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Bhavyasri/IMG_20240727_182913.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Bhavyasri/IMG_20241029_013600.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Bhavyasri/IMG_20241028_223925.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Bhavyasri/IMG-20241029-WA0002.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Bhavyasri/IMG_20240203_152009.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Bhavyasri/IMG_20241028_213013.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Bhavyasri/IMG_20241029_021807.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Harsh/IMG-20241029-WA0049.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Harsh/IMG-20241029-WA0051.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Harsh/IMG-20241029-WA0050.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Harsh/IMG-20241029-WA0052.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Harsh/IMG-20241029-WA0053.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Anand/WhatsApp Image 2024-10-29 at 18.37.31.jpeg', '/Users/narendraraj/fr/final_dataset/resized_faces/Anand/WhatsApp Image 2024-10-29 at 18.37.30.jpeg', '/Users/narendraraj/fr/final_dataset/resized_faces/Anand/WhatsApp Image 2024-10-29 at 18.37.29 (1).jpeg', '/Users/narendraraj/fr/final_dataset/resized_faces/Anand/Anand4.png', '/Users/narendraraj/fr/final_dataset/resized_faces/Anand/Anand10.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Anand/WhatsApp Image 2024-10-29 at 18.37.29.jpeg', '/Users/narendraraj/fr/final_dataset/resized_faces/Anand/Anand7.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Anand/Anand3.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Anand/WhatsApp Image 2024-10-29 at 18.37.28.jpeg', '/Users/narendraraj/fr/final_dataset/resized_faces/Anand/Anand2.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Anand/Anand1.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Anand/WhatsApp Image 2024-10-29 at 18.37.29 (2).jpeg', '/Users/narendraraj/fr/final_dataset/resized_faces/Anand/Anand1.jpeg', '/Users/narendraraj/fr/final_dataset/resized_faces/Gaurav/IMG-20241029-WA0014.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Gaurav/IMG-20241029-WA0016.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Gaurav/IMG-20241029-WA0003.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Gaurav/IMG-20241029-WA0007.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Gaurav/IMG-20241029-WA0012.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Gaurav/IMG-20241029-WA0011.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Gaurav/IMG-20241029-WA0005.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Gaurav/IMG-20241029-WA0009.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Mythili/IMG-20240318-WA0043.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Mythili/IMG-20241029-WA0032.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Mythili/IMG-20241029-WA0033.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Mythili/IMG-20241029-WA0031.jpg']\n",
      "Class names: ['Karan', 'Karan', 'Karan', 'Karan', 'Karan', 'Karan', 'Bhavyasri', 'Bhavyasri', 'Bhavyasri', 'Bhavyasri', 'Bhavyasri', 'Bhavyasri', 'Bhavyasri', 'Bhavyasri', 'Bhavyasri', 'Bhavyasri', 'Bhavyasri', 'Bhavyasri', 'Harsh', 'Harsh', 'Harsh', 'Harsh', 'Harsh', 'Anand', 'Anand', 'Anand', 'Anand', 'Anand', 'Anand', 'Anand', 'Anand', 'Anand', 'Anand', 'Anand', 'Anand', 'Anand', 'Gaurav', 'Gaurav', 'Gaurav', 'Gaurav', 'Gaurav', 'Gaurav', 'Gaurav', 'Gaurav', 'Mythili', 'Mythili', 'Mythili', 'Mythili']\n"
     ]
    }
   ],
   "source": [
    "# Path to the directory with images for encoding\n",
    "path = '/Users/narendraraj/fr/final_dataset/resized_faces'\n",
    "images = []\n",
    "classNames = []\n",
    "# List all items in the specified path and store images and class names\n",
    "def makeClasses():\n",
    "    for cls in os.listdir(path):\n",
    "        cls_path = os.path.join(path, cls)\n",
    "        if os.path.isdir(cls_path):\n",
    "            for img in os.listdir(cls_path):\n",
    "                if not img.endswith('.DS_Store'):\n",
    "                    images.append(os.path.join(cls_path, img))\n",
    "                    classNames.append(cls)\n",
    "    return classNames\n",
    "\n",
    "classNames = makeClasses()\n",
    "\n",
    "print(\"Image files:\", images)\n",
    "print(\"Class names:\", classNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de4c884c-2475-4ac4-b04f-603882751fcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding start\n",
      "encoded image: 1\n",
      "encoded image: 2\n",
      "encoded image: 3\n",
      "encoded image: 4\n",
      "encoded image: 5\n",
      "encoded image: 6\n",
      "encoded image: 7\n",
      "encoded image: 8\n",
      "encoded image: 9\n",
      "encoded image: 10\n",
      "encoded image: 11\n",
      "encoded image: 12\n",
      "encoded image: 13\n",
      "encoded image: 14\n",
      "encoded image: 15\n",
      "encoded image: 16\n",
      "encoded image: 17\n",
      "encoded image: 18\n",
      "encoded image: 19\n",
      "encoded image: 20\n",
      "encoded image: 21\n",
      "encoded image: 22\n",
      "encoded image: 23\n",
      "encoded image: 24\n",
      "encoded image: 25\n",
      "encoded image: 26\n",
      "encoded image: 27\n",
      "encoded image: 28\n",
      "encoded image: 29\n",
      "encoded image: 30\n",
      "encoded image: 31\n",
      "encoded image: 32\n",
      "encoded image: 33\n",
      "encoded image: 34\n",
      "encoded image: 35\n",
      "encoded image: 36\n",
      "encoded image: 37\n",
      "encoded image: 38\n",
      "encoded image: 39\n",
      "encoded image: 40\n",
      "encoded image: 41\n",
      "encoded image: 42\n",
      "encoded image: 43\n",
      "encoded image: 44\n",
      "encoded image: 45\n",
      "encoded image: 46\n",
      "encoded image: 47\n",
      "encoded image: 48\n",
      "Encoding complete. 48 face(s) encoded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Function for encoding faces\n",
    "print(\"encoding start\")\n",
    "counter = 0\n",
    "def findEncodings(images):\n",
    "    global counter\n",
    "    encodeList = []\n",
    "    for img_path in images:\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"Error loading image: {img_path}\")\n",
    "            continue\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        encodes = face_recognition.face_encodings(img)\n",
    "        if encodes:\n",
    "            encodeList.append(encodes[0]) # Use the first encoding if present\n",
    "            counter+=1      \n",
    "            print(f'encoded image: {counter}')\n",
    "        else:\n",
    "            print(f\"No face found in image: {img_path}\")\n",
    "    \n",
    "    # Validation message after processing all images\n",
    "    if encodeList:\n",
    "        print(f\"Encoding complete. {len(encodeList)} face(s) encoded successfully.\")\n",
    "    else:\n",
    "        print(\"Encoding complete. No faces were found in the provided images.\")\n",
    "    \n",
    "    return encodeList\n",
    "\n",
    "encodeListKnown = findEncodings(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5da0c8d6-59d6-4e18-b040-643988d5fd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encodings loaded from file.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# Save or load encodings\n",
    "if not os.path.exists(\"encodings.pkl\"):\n",
    "    encodeListKnown = findEncodings(images)\n",
    "    with open(\"encodings.pkl\", \"wb\") as f:\n",
    "        pickle.dump((encodeListKnown, classNames), f)\n",
    "    print(\"Encodings computed and saved to file.\")\n",
    "else:\n",
    "    with open(\"encodings.pkl\", \"rb\") as f:\n",
    "        encodeListKnown, classNames = pickle.load(f)\n",
    "    print(\"Encodings loaded from file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e906ef6c-6ec2-4b17-a620-091eb7eedc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attendance marking function start\n",
      "Function end\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "print(\"Attendance marking function start\")\n",
    "\n",
    "# Generate a unique filename using the current date and time\n",
    "now = datetime.now()\n",
    "date_str = now.strftime('%Y-%m-%d_%H-%M-%S')\n",
    "attendance_file = f'Attendance_{date_str}.csv'\n",
    "\n",
    "def markAttendance(name):\n",
    "    # Check if the attendance file exists, create it with a header if not\n",
    "    if not os.path.isfile(attendance_file):\n",
    "        with open(attendance_file, 'w') as f:\n",
    "            f.write('Name,Time\\n')  # Create the header\n",
    "\n",
    "    with open(attendance_file, 'a+') as f:\n",
    "        f.seek(0)  # Move to the beginning of the file to read\n",
    "        myDateList = f.readlines()\n",
    "        nameList = [line.split(',')[0] for line in myDateList[1:]]  # Skip header to get names only\n",
    "        if name not in nameList:\n",
    "            now = datetime.now()\n",
    "            dtString = now.strftime('%H:%M:%S')\n",
    "            f.write(f'{name},{dtString}\\n')  # Append attendance\n",
    "\n",
    "print(\"Function end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cbada9a-5f4f-4c23-b6c2-157b869459e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "--------------------\n",
      "Number of faces encoded: 48\n",
      "Encoding vector dimension: 128\n",
      "Number of unique classes: 6\n",
      "All class names: ['Gaurav', 'Bhavyasri', 'Harsh', 'Karan', 'Mythili', 'Anand']\n",
      "\n",
      "Class Distribution:\n",
      " - Gaurav: 16 instances\n",
      " - Bhavyasri: 24 instances\n",
      " - Harsh: 10 instances\n",
      " - Karan: 12 instances\n",
      " - Mythili: 8 instances\n",
      " - Anand: 26 instances\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "className = makeClasses()\n",
    "unique_ClassNames = set(classNames)  # Set of unique class names\n",
    "\n",
    "def model_summary(encodeListKnown, unique_ClassNames):\n",
    "    print(\"Model Summary:\")\n",
    "    print(\"--------------------\")\n",
    "    \n",
    "    # Basic Details\n",
    "    num_faces_encoded = len(encodeListKnown)\n",
    "    encoding_dim = len(encodeListKnown[0]) if encodeListKnown else 'N/A'\n",
    "    \n",
    "    # Display Basic Information\n",
    "    print(f\"Number of faces encoded: {num_faces_encoded}\")\n",
    "    print(f\"Encoding vector dimension: {encoding_dim}\")\n",
    "    print(f\"Number of unique classes: {len(unique_ClassNames)}\")\n",
    "    \n",
    "    # Class Information\n",
    "    print(\"All class names:\", list(unique_ClassNames))  # Print all unique class names\n",
    "    \n",
    "    # Distribution of Classes\n",
    "    class_counts = {class_name: classNames.count(class_name) for class_name in unique_ClassNames}\n",
    "    print(\"\\nClass Distribution:\")\n",
    "    for class_name, count in class_counts.items():\n",
    "        print(f\" - {class_name}: {count} instances\")\n",
    "    \n",
    "    print(\"--------------------\")\n",
    "\n",
    "# Call the function with your data\n",
    "model_summary(encodeListKnown, unique_ClassNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c944e61-939d-4f5e-9054-0e6e0a2e23ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting capture...\n",
      "\n",
      "Final Recognized Set:\n",
      "{'ANAND', 'GAURAV', 'KARAN'}\n",
      "\n",
      "Recognition Details (Name and Average Distance):\n",
      "     Name  Distance\n",
      "0   ANAND  0.256081\n",
      "1  GAURAV  0.311596\n",
      "2   KARAN  0.281921\n"
     ]
    }
   ],
   "source": [
    "# Initialize the webcam capture\n",
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Starting capture...\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "Student_Set = set()\n",
    "\n",
    "# Number of iterations for averaging\n",
    "num_iterations = 20\n",
    "distance_records = []\n",
    "\n",
    "name_distance_list = []  # To store names and corresponding average distances\n",
    "\n",
    "counter = 0\n",
    "# counter < 20\n",
    "while True:\n",
    "    counter += 1\n",
    "    success, img = cap.read()\n",
    "    if not success:\n",
    "        print(\"Failed to capture image.\")\n",
    "        break\n",
    "    \n",
    "    imgSmall = cv2.resize(img, (0, 0), fx=0.25, fy=0.25)\n",
    "    imgSmall = cv2.cvtColor(imgSmall, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect faces and encode them\n",
    "    facesCurrFrame = face_recognition.face_locations(imgSmall)\n",
    "    encodesCurrFrame = face_recognition.face_encodings(imgSmall, facesCurrFrame)\n",
    "\n",
    "    for encodeFace, faceLoc in zip(encodesCurrFrame, facesCurrFrame):\n",
    "        matches = face_recognition.compare_faces(encodeListKnown, encodeFace)\n",
    "        faceDis = face_recognition.face_distance(encodeListKnown, encodeFace)\n",
    "        matchIndex = np.argmin(faceDis)\n",
    "\n",
    "        # Store distances for averaging\n",
    "        distance_records.append(faceDis[matchIndex])\n",
    "\n",
    "        # Keep only the last num_iterations distances\n",
    "        if len(distance_records) > num_iterations:\n",
    "            distance_records.pop(0)\n",
    "\n",
    "        # Calculate the average distance\n",
    "        average_distance = np.mean(distance_records)\n",
    "        # print(average_distance)\n",
    "        \n",
    "        # Set your recognition threshold\n",
    "        threshold = 0.4  # You can adjust this value based on your needs\n",
    "\n",
    "        if matches[matchIndex] and average_distance < threshold:\n",
    "            name = classNames[matchIndex].upper()\n",
    "            Student_Set.add(name)\n",
    "            name_distance_list.append({'Name': name, 'Distance': average_distance})\n",
    "\n",
    "            # Draw rectangle around recognized face\n",
    "            y1, x2, y2, x1 = faceLoc\n",
    "            cv2.rectangle(img, (x1*4, y1*4), (x2*4, y2*4), (0, 255, 0), 2)\n",
    "            cv2.rectangle(img, (x1*4, y2*4 - 35), (x2*4, y2*4), (0, 255, 0), cv2.FILLED)\n",
    "            cv2.putText(img, name, (x1*4 + 6, y2*4 - 6), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2)\n",
    "            markAttendance(name)\n",
    "\n",
    "    # Show the captured image with any recognized face\n",
    "    cv2.imshow('Webcam', img)\n",
    "    \n",
    "    # Exit the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Display final set of recognized names\n",
    "print(\"\\nFinal Recognized Set:\")\n",
    "print(Student_Set)\n",
    "\n",
    "# Display the tabulated output of names and distances\n",
    "if name_distance_list:\n",
    "    df = pd.DataFrame(name_distance_list)\n",
    "    print(\"\\nRecognition Details (Name and Average Distance):\")\n",
    "    print(df.groupby('Name').min().reset_index())  # Show unique names with minimum distance recorded\n",
    "\n",
    "# Release the capture and destroy all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19ef3b9-c6a0-4b9a-88cb-20696d5d2373",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

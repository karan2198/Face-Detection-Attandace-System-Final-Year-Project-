{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0295ade0-bffd-4d55-b3d5-8841b2a7c22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cmake in ./env/lib/python3.12/site-packages (3.30.5)\n",
      "Requirement already satisfied: dlib in ./env/lib/python3.12/site-packages (19.24.6)\n",
      "Requirement already satisfied: opencv-python in ./env/lib/python3.12/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy in ./env/lib/python3.12/site-packages (2.1.2)\n",
      "Requirement already satisfied: face-recognition in ./env/lib/python3.12/site-packages (1.3.0)\n",
      "Requirement already satisfied: matplotlib in ./env/lib/python3.12/site-packages (3.9.2)\n",
      "Requirement already satisfied: pillow in ./env/lib/python3.12/site-packages (11.0.0)\n",
      "Requirement already satisfied: face-recognition-models>=0.3.0 in ./env/lib/python3.12/site-packages (from face-recognition) (0.3.0)\n",
      "Requirement already satisfied: Click>=6.0 in ./env/lib/python3.12/site-packages (from face-recognition) (8.1.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./env/lib/python3.12/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./env/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./env/lib/python3.12/site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./env/lib/python3.12/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in ./env/lib/python3.12/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./env/lib/python3.12/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./env/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./env/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install cmake dlib opencv-python numpy face-recognition matplotlib pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cc84dd1-321a-46bd-952e-2ad6e2f117e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Karan/IMG-20241018-WA0022.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Karan/IMG-20241018-WA0023.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Karan/karan.jpeg.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Karan/IMG-20241018-WA0021.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Karan/IMG-20241018-WA0024.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Karan/WhatsApp Image 2024-10-18 at 11.20.57_f8a09022.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Karan/IMG-20241018-WA0019.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Bhavyasri/IMG_20241028_221201.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Bhavyasri/Snapchat-793809341.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Bhavyasri/IMG_20241028_212627.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Bhavyasri/1730133938782_yfp2ux_2_0.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Bhavyasri/IMG-20230218-WA0020.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Bhavyasri/IMG_20240727_182913.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Bhavyasri/IMG_20241029_013600.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Bhavyasri/IMG_20241028_223925.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Bhavyasri/IMG-20241029-WA0002.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Bhavyasri/IMG_20240203_152009.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Bhavyasri/IMG_20241028_213013.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Bhavyasri/Polish_20241029_013429050.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Bhavyasri/IMG_20241028_220946.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Bhavyasri/IMG_20241028_212832.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Bhavyasri/IMG_20241029_021807.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Harsh/IMG-20241029-WA0049.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Harsh/.DS_Store\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Harsh/IMG-20241029-WA0051.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Harsh/IMG-20241029-WA0050.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Harsh/IMG-20241029-WA0052.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Harsh/IMG-20241029-WA0053.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Anand/.DS_Store\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Anand/WhatsApp Image 2024-10-29 at 18.37.31.jpeg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Anand/WhatsApp Image 2024-10-29 at 18.37.30.jpeg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Anand/WhatsApp Image 2024-10-29 at 18.37.29 (1).jpeg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Anand/Anand4.png\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Anand/Anand10.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Anand/WhatsApp Image 2024-10-29 at 18.37.29.jpeg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Anand/Anand7.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Anand/Anand3.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Anand/WhatsApp Image 2024-10-29 at 18.37.28.jpeg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Anand/Anand2.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Anand/Anand1.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Anand/WhatsApp Image 2024-10-29 at 18.37.29 (2).jpeg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Anand/Anand1.jpeg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Gaurav/.DS_Store\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Gaurav/IMG-20241029-WA0014.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Gaurav/IMG-20241029-WA0016.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Gaurav/IMG-20241029-WA0003.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Gaurav/IMG-20241029-WA0007.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Gaurav/IMG-20241029-WA0006.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Gaurav/IMG-20241029-WA0012.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Gaurav/IMG-20241029-WA0010.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Gaurav/IMG-20241029-WA0011.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Gaurav/IMG-20241029-WA0005.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Gaurav/IMG-20241029-WA0009.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Gaurav/IMG-20241029-WA0018.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Mythili/.DS_Store\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Mythili/IMG-20240318-WA0043.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Mythili/IMG-20241029-WA0032.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Mythili/IMG-20241029-WA0033.jpg\n",
      "Image being Cropped: /Users/narendraraj/fr/final_dataset/dataset/Mythili/IMG-20241029-WA0031.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def detect_and_crop_faces(input_folder, output_folder):\n",
    "    # Load OpenCV's Haar Cascade for face detection\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    # Create output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Iterate over all subfolders in the input folder\n",
    "    for person_folder in os.listdir(input_folder):\n",
    "        person_input_path = os.path.join(input_folder, person_folder)\n",
    "\n",
    "        # Check if it's a directory (skip files)\n",
    "        if os.path.isdir(person_input_path):\n",
    "            person_output_path = os.path.join(output_folder, person_folder)\n",
    "\n",
    "            if not os.path.exists(person_output_path):\n",
    "                os.makedirs(person_output_path)\n",
    "\n",
    "            # Process all images in each person's folder\n",
    "            for filename in os.listdir(person_input_path):\n",
    "                image_path = os.path.join(person_input_path, filename)\n",
    "                img = cv2.imread(image_path)\n",
    "\n",
    "                print(f\"Image being Cropped: {image_path}\")\n",
    "                \n",
    "                # Check if image is read successfully\n",
    "                if img is not None:\n",
    "                    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                    \n",
    "                    # Detect faces in the image\n",
    "                    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "                    \n",
    "                    # Crop and save each detected face\n",
    "                    for (x, y, w, h) in faces:\n",
    "                        face_img = img[y:y+h, x:x+w]\n",
    "                        face_filename = os.path.join(person_output_path, filename)\n",
    "                        cv2.imwrite(face_filename, face_img)\n",
    "\n",
    "# Example usage for detecting and cropping faces from multiple folders\n",
    "input_folder = '/Users/narendraraj/fr/final_dataset/dataset'\n",
    "output_folder = '/Users/narendraraj/fr/final_dataset/cropped_faces'\n",
    "\n",
    "detect_and_crop_faces(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c0c058c-6202-42b9-8193-07be1873a9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Karan/IMG-20241018-WA0022.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Karan/IMG-20241018-WA0023.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Karan/karan.jpeg.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Karan/IMG-20241018-WA0021.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Karan/WhatsApp Image 2024-10-18 at 11.20.57_f8a09022.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Karan/IMG-20241018-WA0019.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Bhavyasri/IMG_20241028_221201.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Bhavyasri/Snapchat-793809341.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Bhavyasri/.DS_Store\n",
      "Skipping file: /Users/narendraraj/fr/final_dataset/cropped_faces/Bhavyasri/.DS_Store, not a valid image\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Bhavyasri/IMG_20241028_212627.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Bhavyasri/1730133938782_yfp2ux_2_0.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Bhavyasri/IMG-20230218-WA0020.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Bhavyasri/IMG_20240727_182913.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Bhavyasri/IMG_20241029_013600.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Bhavyasri/IMG_20241028_223925.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Bhavyasri/IMG-20241029-WA0002.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Bhavyasri/IMG_20240203_152009.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Bhavyasri/IMG_20241028_213013.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Bhavyasri/Polish_20241029_013429050.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Bhavyasri/IMG_20241028_220946.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Bhavyasri/IMG_20241028_212832.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Bhavyasri/IMG_20241029_021807.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Harsh/IMG-20241029-WA0049.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Harsh/IMG-20241029-WA0051.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Harsh/IMG-20241029-WA0050.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Harsh/IMG-20241029-WA0052.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Harsh/IMG-20241029-WA0053.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Anand/WhatsApp Image 2024-10-29 at 18.37.31.jpeg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Anand/WhatsApp Image 2024-10-29 at 18.37.30.jpeg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Anand/WhatsApp Image 2024-10-29 at 18.37.29 (1).jpeg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Anand/Anand4.png\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Anand/Anand10.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Anand/WhatsApp Image 2024-10-29 at 18.37.29.jpeg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Anand/Anand7.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Anand/Anand3.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Anand/WhatsApp Image 2024-10-29 at 18.37.28.jpeg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Anand/Anand2.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Anand/Anand1.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Anand/WhatsApp Image 2024-10-29 at 18.37.29 (2).jpeg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Anand/Anand1.jpeg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Gaurav/.DS_Store\n",
      "Skipping file: /Users/narendraraj/fr/final_dataset/cropped_faces/Gaurav/.DS_Store, not a valid image\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Gaurav/IMG-20241029-WA0014.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Gaurav/IMG-20241029-WA0016.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Gaurav/IMG-20241029-WA0003.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Gaurav/IMG-20241029-WA0007.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Gaurav/IMG-20241029-WA0006.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Gaurav/IMG-20241029-WA0012.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Gaurav/IMG-20241029-WA0010.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Gaurav/IMG-20241029-WA0011.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Gaurav/IMG-20241029-WA0005.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Gaurav/IMG-20241029-WA0009.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Gaurav/IMG-20241029-WA0018.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Mythili/IMG-20240318-WA0043.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Mythili/IMG-20241029-WA0032.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Mythili/IMG-20241029-WA0033.jpg\n",
      "Resizing Image: /Users/narendraraj/fr/final_dataset/cropped_faces/Mythili/IMG-20241029-WA0031.jpg\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def resize_images(input_folder, output_folder, size=(224, 224)):\n",
    "    # Create output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # Iterate over each subfolder (person's folder) in the input folder\n",
    "    for person_folder in os.listdir(input_folder):\n",
    "        person_input_path = os.path.join(input_folder, person_folder)\n",
    "        person_output_path = os.path.join(output_folder, person_folder)\n",
    "\n",
    "        # Check if it's a directory (skip files)\n",
    "        if os.path.isdir(person_input_path):\n",
    "            if not os.path.exists(person_output_path):\n",
    "                os.makedirs(person_output_path)\n",
    "\n",
    "            # Process each image in the person's folder\n",
    "            for filename in os.listdir(person_input_path):\n",
    "                image_path = os.path.join(person_input_path, filename)\n",
    "\n",
    "                print(f\"Resizing Image: {image_path}\")\n",
    "\n",
    "                # Try to open the image, skip if it's not an image file\n",
    "                try:\n",
    "                    img = Image.open(image_path)\n",
    "                    img_resized = img.resize(size)\n",
    "                    img_resized.save(os.path.join(person_output_path, filename))\n",
    "                except (IOError, OSError):\n",
    "                    print(f\"Skipping file: {image_path}, not a valid image\")\n",
    "\n",
    "# Example usage to resize images in multiple subfolders\n",
    "input_folder = '/Users/narendraraj/fr/final_dataset/cropped_faces'\n",
    "output_folder = '/Users/narendraraj/fr/final_dataset/resized_faces'\n",
    "\n",
    "resize_images(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eda103c-8acd-4e44-b7e3-855e79e4e602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The lines `import cv2`, `import numpy as np`, and `import face_recognition` are importing necessary\n",
    "# libraries in Python for image processing and face recognition tasks.\n",
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import os\n",
    "import pickle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d865cf8c-e8ca-4050-b735-257a03451468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image files: ['/Users/narendraraj/fr/final_dataset/resized_faces/Karan/IMG-20241018-WA0022.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Karan/IMG-20241018-WA0023.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Karan/karan.jpeg.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Karan/IMG-20241018-WA0021.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Karan/WhatsApp Image 2024-10-18 at 11.20.57_f8a09022.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Karan/IMG-20241018-WA0019.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Bhavyasri/IMG_20241028_221201.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Bhavyasri/Snapchat-793809341.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Bhavyasri/IMG_20241028_212627.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Bhavyasri/1730133938782_yfp2ux_2_0.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Bhavyasri/IMG-20230218-WA0020.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Bhavyasri/IMG_20240727_182913.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Bhavyasri/IMG_20241029_013600.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Bhavyasri/IMG_20241028_223925.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Bhavyasri/IMG-20241029-WA0002.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Bhavyasri/IMG_20240203_152009.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Bhavyasri/IMG_20241028_213013.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Bhavyasri/Polish_20241029_013429050.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Bhavyasri/IMG_20241028_220946.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Bhavyasri/IMG_20241028_212832.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Bhavyasri/IMG_20241029_021807.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Harsh/IMG-20241029-WA0049.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Harsh/IMG-20241029-WA0051.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Harsh/IMG-20241029-WA0050.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Harsh/IMG-20241029-WA0052.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Harsh/IMG-20241029-WA0053.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Anand/WhatsApp Image 2024-10-29 at 18.37.31.jpeg', '/Users/narendraraj/fr/final_dataset/resized_faces/Anand/WhatsApp Image 2024-10-29 at 18.37.30.jpeg', '/Users/narendraraj/fr/final_dataset/resized_faces/Anand/WhatsApp Image 2024-10-29 at 18.37.29 (1).jpeg', '/Users/narendraraj/fr/final_dataset/resized_faces/Anand/Anand4.png', '/Users/narendraraj/fr/final_dataset/resized_faces/Anand/Anand10.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Anand/WhatsApp Image 2024-10-29 at 18.37.29.jpeg', '/Users/narendraraj/fr/final_dataset/resized_faces/Anand/Anand7.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Anand/Anand3.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Anand/WhatsApp Image 2024-10-29 at 18.37.28.jpeg', '/Users/narendraraj/fr/final_dataset/resized_faces/Anand/Anand2.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Anand/Anand1.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Anand/WhatsApp Image 2024-10-29 at 18.37.29 (2).jpeg', '/Users/narendraraj/fr/final_dataset/resized_faces/Anand/Anand1.jpeg', '/Users/narendraraj/fr/final_dataset/resized_faces/Gaurav/IMG-20241029-WA0014.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Gaurav/IMG-20241029-WA0016.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Gaurav/IMG-20241029-WA0003.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Gaurav/IMG-20241029-WA0007.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Gaurav/IMG-20241029-WA0006.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Gaurav/IMG-20241029-WA0012.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Gaurav/IMG-20241029-WA0010.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Gaurav/IMG-20241029-WA0011.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Gaurav/IMG-20241029-WA0005.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Gaurav/IMG-20241029-WA0009.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Gaurav/IMG-20241029-WA0018.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Mythili/IMG-20240318-WA0043.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Mythili/IMG-20241029-WA0032.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Mythili/IMG-20241029-WA0033.jpg', '/Users/narendraraj/fr/final_dataset/resized_faces/Mythili/IMG-20241029-WA0031.jpg']\n",
      "Class names: ['Karan', 'Karan', 'Karan', 'Karan', 'Karan', 'Karan', 'Bhavyasri', 'Bhavyasri', 'Bhavyasri', 'Bhavyasri', 'Bhavyasri', 'Bhavyasri', 'Bhavyasri', 'Bhavyasri', 'Bhavyasri', 'Bhavyasri', 'Bhavyasri', 'Bhavyasri', 'Bhavyasri', 'Bhavyasri', 'Bhavyasri', 'Harsh', 'Harsh', 'Harsh', 'Harsh', 'Harsh', 'Anand', 'Anand', 'Anand', 'Anand', 'Anand', 'Anand', 'Anand', 'Anand', 'Anand', 'Anand', 'Anand', 'Anand', 'Anand', 'Gaurav', 'Gaurav', 'Gaurav', 'Gaurav', 'Gaurav', 'Gaurav', 'Gaurav', 'Gaurav', 'Gaurav', 'Gaurav', 'Gaurav', 'Mythili', 'Mythili', 'Mythili', 'Mythili']\n"
     ]
    }
   ],
   "source": [
    "# Path to the directory with images for encoding\n",
    "path = '/Users/narendraraj/fr/final_dataset/resized_faces'\n",
    "images = []\n",
    "classNames = []\n",
    "# List all items in the specified path and store images and class names\n",
    "def makeClasses():\n",
    "    for cls in os.listdir(path):\n",
    "        cls_path = os.path.join(path, cls)\n",
    "        if os.path.isdir(cls_path):\n",
    "            for img in os.listdir(cls_path):\n",
    "                if not img.endswith('.DS_Store'):\n",
    "                    images.append(os.path.join(cls_path, img))\n",
    "                    classNames.append(cls)\n",
    "    return classNames\n",
    "\n",
    "classNames = makeClasses()\n",
    "\n",
    "print(\"Image files:\", images)\n",
    "print(\"Class names:\", classNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de4c884c-2475-4ac4-b04f-603882751fcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding start\n",
      "encoded image: 1\n",
      "encoded image: 2\n",
      "encoded image: 3\n",
      "encoded image: 4\n",
      "encoded image: 5\n",
      "encoded image: 6\n",
      "encoded image: 7\n",
      "encoded image: 8\n",
      "encoded image: 9\n",
      "encoded image: 10\n",
      "encoded image: 11\n",
      "encoded image: 12\n",
      "encoded image: 13\n",
      "encoded image: 14\n",
      "encoded image: 15\n",
      "encoded image: 16\n",
      "encoded image: 17\n",
      "No face found in image: /Users/narendraraj/fr/final_dataset/resized_faces/Bhavyasri/Polish_20241029_013429050.jpg\n",
      "encoded image: 18\n",
      "No face found in image: /Users/narendraraj/fr/final_dataset/resized_faces/Bhavyasri/IMG_20241028_212832.jpg\n",
      "encoded image: 19\n",
      "encoded image: 20\n",
      "encoded image: 21\n",
      "encoded image: 22\n",
      "encoded image: 23\n",
      "encoded image: 24\n",
      "encoded image: 25\n",
      "encoded image: 26\n",
      "encoded image: 27\n",
      "encoded image: 28\n",
      "encoded image: 29\n",
      "encoded image: 30\n",
      "encoded image: 31\n",
      "encoded image: 32\n",
      "encoded image: 33\n",
      "encoded image: 34\n",
      "encoded image: 35\n",
      "encoded image: 36\n",
      "encoded image: 37\n",
      "encoded image: 38\n",
      "encoded image: 39\n",
      "encoded image: 40\n",
      "encoded image: 41\n",
      "No face found in image: /Users/narendraraj/fr/final_dataset/resized_faces/Gaurav/IMG-20241029-WA0006.jpg\n",
      "encoded image: 42\n",
      "No face found in image: /Users/narendraraj/fr/final_dataset/resized_faces/Gaurav/IMG-20241029-WA0010.jpg\n",
      "encoded image: 43\n",
      "encoded image: 44\n",
      "encoded image: 45\n",
      "No face found in image: /Users/narendraraj/fr/final_dataset/resized_faces/Gaurav/IMG-20241029-WA0018.jpg\n",
      "encoded image: 46\n",
      "encoded image: 47\n",
      "encoded image: 48\n",
      "encoded image: 49\n",
      "Encoding complete. 49 face(s) encoded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Function for encoding faces\n",
    "print(\"encoding start\")\n",
    "counter = 0\n",
    "def findEncodings(images):\n",
    "    global counter\n",
    "    encodeList = []\n",
    "    for img_path in images:\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"Error loading image: {img_path}\")\n",
    "            continue\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        encodes = face_recognition.face_encodings(img)\n",
    "        if encodes:\n",
    "            encodeList.append(encodes[0]) # Use the first encoding if present\n",
    "            counter+=1      \n",
    "            print(f'encoded image: {counter}')\n",
    "        else:\n",
    "            print(f\"No face found in image: {img_path}\")\n",
    "    \n",
    "    # Validation message after processing all images\n",
    "    if encodeList:\n",
    "        print(f\"Encoding complete. {len(encodeList)} face(s) encoded successfully.\")\n",
    "    else:\n",
    "        print(\"Encoding complete. No faces were found in the provided images.\")\n",
    "    \n",
    "    return encodeList\n",
    "\n",
    "encodeListKnown = findEncodings(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5da0c8d6-59d6-4e18-b040-643988d5fd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encodings loaded from file.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# Save or load encodings\n",
    "if not os.path.exists(\"encodings.pkl\"):\n",
    "    encodeListKnown = findEncodings(images)\n",
    "    with open(\"encodings.pkl\", \"wb\") as f:\n",
    "        pickle.dump((encodeListKnown, classNames), f)\n",
    "    print(\"Encodings computed and saved to file.\")\n",
    "else:\n",
    "    with open(\"encodings.pkl\", \"rb\") as f:\n",
    "        encodeListKnown, classNames = pickle.load(f)\n",
    "    print(\"Encodings loaded from file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e906ef6c-6ec2-4b17-a620-091eb7eedc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attendance marking function start\n",
      "Function end\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "print(\"Attendance marking function start\")\n",
    "\n",
    "# Generate a unique filename using the current date and time\n",
    "now = datetime.now()\n",
    "date_str = now.strftime('%Y-%m-%d_%H-%M-%S')\n",
    "attendance_file = f'Attendance_{date_str}.csv'\n",
    "\n",
    "def markAttendance(name):\n",
    "    # Check if the attendance file exists, create it with a header if not\n",
    "    if not os.path.isfile(attendance_file):\n",
    "        with open(attendance_file, 'w') as f:\n",
    "            f.write('Name,Time\\n')  # Create the header\n",
    "\n",
    "    with open(attendance_file, 'a+') as f:\n",
    "        f.seek(0)  # Move to the beginning of the file to read\n",
    "        myDateList = f.readlines()\n",
    "        nameList = [line.split(',')[0] for line in myDateList[1:]]  # Skip header to get names only\n",
    "        if name not in nameList:\n",
    "            now = datetime.now()\n",
    "            dtString = now.strftime('%H:%M:%S')\n",
    "            f.write(f'{name},{dtString}\\n')  # Append attendance\n",
    "\n",
    "print(\"Function end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cbada9a-5f4f-4c23-b6c2-157b869459e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "--------------------\n",
      "Number of faces encoded: 48\n",
      "Encoding vector dimension: 128\n",
      "Number of unique classes: 6\n",
      "All class names: ['Harsh', 'Anand', 'Karan', 'Bhavyasri', 'Gaurav', 'Mythili']\n",
      "\n",
      "Class Distribution:\n",
      " - Harsh: 10 instances\n",
      " - Anand: 26 instances\n",
      " - Karan: 12 instances\n",
      " - Bhavyasri: 27 instances\n",
      " - Gaurav: 19 instances\n",
      " - Mythili: 8 instances\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "className = makeClasses()\n",
    "unique_ClassNames = set(classNames)  # Set of unique class names\n",
    "\n",
    "def model_summary(encodeListKnown, unique_ClassNames):\n",
    "    print(\"Model Summary:\")\n",
    "    print(\"--------------------\")\n",
    "    \n",
    "    # Basic Details\n",
    "    num_faces_encoded = len(encodeListKnown)\n",
    "    encoding_dim = len(encodeListKnown[0]) if encodeListKnown else 'N/A'\n",
    "    \n",
    "    # Display Basic Information\n",
    "    print(f\"Number of faces encoded: {num_faces_encoded}\")\n",
    "    print(f\"Encoding vector dimension: {encoding_dim}\")\n",
    "    print(f\"Number of unique classes: {len(unique_ClassNames)}\")\n",
    "    \n",
    "    # Class Information\n",
    "    print(\"All class names:\", list(unique_ClassNames))  # Print all unique class names\n",
    "    \n",
    "    # Distribution of Classes\n",
    "    class_counts = {class_name: classNames.count(class_name) for class_name in unique_ClassNames}\n",
    "    print(\"\\nClass Distribution:\")\n",
    "    for class_name, count in class_counts.items():\n",
    "        print(f\" - {class_name}: {count} instances\")\n",
    "    \n",
    "    print(\"--------------------\")\n",
    "\n",
    "# Call the function with your data\n",
    "model_summary(encodeListKnown, unique_ClassNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c944e61-939d-4f5e-9054-0e6e0a2e23ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting capture...\n",
      "\n",
      "Final Recognized Set:\n",
      "{'ANAND'}\n",
      "\n",
      "Recognition Details (Name and Average Distance):\n",
      "    Name  Distance\n",
      "0  ANAND  0.284483\n"
     ]
    }
   ],
   "source": [
    "# Initialize the webcam capture\n",
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Starting capture...\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "Student_Set = set()\n",
    "\n",
    "# Number of iterations for averaging\n",
    "num_iterations = 20\n",
    "distance_records = []\n",
    "\n",
    "name_distance_list = []  # To store names and corresponding average distances\n",
    "\n",
    "counter = 0\n",
    "# counter < 20\n",
    "while True:\n",
    "    counter += 1\n",
    "    success, img = cap.read()\n",
    "    if not success:\n",
    "        print(\"Failed to capture image.\")\n",
    "        break\n",
    "    \n",
    "    imgSmall = cv2.resize(img, (0, 0), fx=0.25, fy=0.25)\n",
    "    imgSmall = cv2.cvtColor(imgSmall, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect faces and encode them\n",
    "    facesCurrFrame = face_recognition.face_locations(imgSmall)\n",
    "    encodesCurrFrame = face_recognition.face_encodings(imgSmall, facesCurrFrame)\n",
    "\n",
    "    for encodeFace, faceLoc in zip(encodesCurrFrame, facesCurrFrame):\n",
    "        matches = face_recognition.compare_faces(encodeListKnown, encodeFace)\n",
    "        faceDis = face_recognition.face_distance(encodeListKnown, encodeFace)\n",
    "        matchIndex = np.argmin(faceDis)\n",
    "\n",
    "        # Store distances for averaging\n",
    "        distance_records.append(faceDis[matchIndex])\n",
    "\n",
    "        # Keep only the last num_iterations distances\n",
    "        if len(distance_records) > num_iterations:\n",
    "            distance_records.pop(0)\n",
    "\n",
    "        # Calculate the average distance\n",
    "        average_distance = np.mean(distance_records)\n",
    "        # print(average_distance)\n",
    "        \n",
    "        # Set your recognition threshold\n",
    "        threshold = 0.4  # You can adjust this value based on your needs\n",
    "\n",
    "        if matches[matchIndex] and average_distance < threshold:\n",
    "            name = classNames[matchIndex].upper()\n",
    "            Student_Set.add(name)\n",
    "            name_distance_list.append({'Name': name, 'Distance': average_distance})\n",
    "\n",
    "            # Draw rectangle around recognized face\n",
    "            y1, x2, y2, x1 = faceLoc\n",
    "            cv2.rectangle(img, (x1*4, y1*4), (x2*4, y2*4), (0, 255, 0), 2)\n",
    "            cv2.rectangle(img, (x1*4, y2*4 - 35), (x2*4, y2*4), (0, 255, 0), cv2.FILLED)\n",
    "            cv2.putText(img, name, (x1*4 + 6, y2*4 - 6), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2)\n",
    "            markAttendance(name)\n",
    "\n",
    "    # Show the captured image with any recognized face\n",
    "    cv2.imshow('Webcam', img)\n",
    "    \n",
    "    # Exit the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Display final set of recognized names\n",
    "print(\"\\nFinal Recognized Set:\")\n",
    "print(Student_Set)\n",
    "\n",
    "# Display the tabulated output of names and distances\n",
    "if name_distance_list:\n",
    "    df = pd.DataFrame(name_distance_list)\n",
    "    print(\"\\nRecognition Details (Name and Average Distance):\")\n",
    "    print(df.groupby('Name').min().reset_index())  # Show unique names with minimum distance recorded\n",
    "\n",
    "# Release the capture and destroy all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e19ef3b9-c6a0-4b9a-88cb-20696d5d2373",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Assuming `images` is a list of image paths\u001b[39;00m\n\u001b[1;32m      5\u001b[0m pred_boxes_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_path \u001b[38;5;129;01min\u001b[39;00m \u001b[43mimages\u001b[49m:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Load image using OpenCV\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image_path)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Convert the image from BGR to RGB (since OpenCV loads images in BGR by default)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2  # OpenCV to load images as numpy arrays\n",
    "\n",
    "# Assuming `images` is a list of image paths\n",
    "pred_boxes_list = []\n",
    "for image_path in images:\n",
    "    # Load image using OpenCV\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert the image from BGR to RGB (since OpenCV loads images in BGR by default)\n",
    "    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect face locations (bounding boxes)\n",
    "    face_locations = face_recognition.face_locations(rgb_image)\n",
    "\n",
    "    # Convert face locations into bounding box format (x_min, y_min, x_max, y_max)\n",
    "    pred_boxes = [(top, right, bottom, left) for (top, right, bottom, left) in face_locations]\n",
    "    \n",
    "    # You can also apply a confidence threshold if needed (although face_recognition doesn't provide confidence scores directly)\n",
    "    pred_boxes_list.append(pred_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec0cce36-4819-400a-a25a-c720312c34f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "\n",
    "gt_boxes_list = []\n",
    "\n",
    "# Assuming images are paths to LFW dataset images\n",
    "for image_path in images:\n",
    "    # Load image using OpenCV\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert the image from BGR to RGB (since OpenCV loads images in BGR by default)\n",
    "    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect face locations (bounding boxes)\n",
    "    face_locations = face_recognition.face_locations(rgb_image)\n",
    "\n",
    "    # Convert face locations into bounding box format (top, right, bottom, left)\n",
    "    gt_boxes = [(top, right, bottom, left) for (top, right, bottom, left) in face_locations]\n",
    "\n",
    "    # Append the gt_boxes for the current image to the list\n",
    "    gt_boxes_list.append(gt_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f02d261-21d8-4f73-8db4-d674d427bb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean Average Precision (mAP) : 0.907\n",
      "mean Average Recall (mAP) : 0.907\n",
      "mean Average F1 Score (mAF1) : 0.907\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# IoU Calculation\n",
    "def calculate_iou(pred_box, gt_box):\n",
    "    # Convert (top, right, bottom, left) to (x_min, y_min, x_max, y_max)\n",
    "    pred_box = [pred_box[3], pred_box[0], pred_box[1], pred_box[2]]\n",
    "    gt_box = [gt_box[3], gt_box[0], gt_box[1], gt_box[2]]\n",
    "    \n",
    "    # Determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(pred_box[0], gt_box[0])\n",
    "    yA = max(pred_box[1], gt_box[1])\n",
    "    xB = min(pred_box[2], gt_box[2])\n",
    "    yB = min(pred_box[3], gt_box[3])\n",
    "\n",
    "    # Compute the area of intersection rectangle\n",
    "    inter_area = max(0, xB - xA) * max(0, yB - yA)\n",
    "    \n",
    "    # Calculate areas of predicted and ground-truth bounding boxes\n",
    "    pred_area = (pred_box[2] - pred_box[0]) * (pred_box[3] - pred_box[1])\n",
    "    gt_area = (gt_box[2] - gt_box[0]) * (gt_box[3] - gt_box[1])\n",
    "    \n",
    "    # Compute the Intersection over Union (IoU)\n",
    "    iou = inter_area / float(pred_area + gt_area - inter_area) if (pred_area + gt_area - inter_area) > 0 else 0\n",
    "    return iou\n",
    "\n",
    "# Precision, Recall, and F1 Score calculation\n",
    "def calculate_precision_recall_f1(pred_boxes, gt_boxes, iou_threshold=0.5):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "\n",
    "    # Compare each predicted box to each ground-truth box\n",
    "    for gt_box in gt_boxes:\n",
    "        match_found = False\n",
    "        for pred_box in pred_boxes:\n",
    "            iou = calculate_iou(pred_box, gt_box)\n",
    "            # print(f\"IoU between {pred_box} and {gt_box}: {iou}\")  # Debugging output\n",
    "            if iou >= iou_threshold:\n",
    "                tp += 1\n",
    "                match_found = True\n",
    "                break\n",
    "        if not match_found:\n",
    "            fn += 1\n",
    "\n",
    "    # Unmatched predictions are false positives\n",
    "    fp = len(pred_boxes) - tp\n",
    "\n",
    "    # Calculate Precision, Recall, and F1 Score\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    return precision, recall, f1_score\n",
    "\n",
    "# mAP Calculation\n",
    "def calculate_map(pred_boxes_list, gt_boxes_list, iou_threshold=0.5):\n",
    "    precision_sum = 0\n",
    "    recall_sum = 0\n",
    "    f1_sum = 0\n",
    "    count = len(pred_boxes_list)\n",
    "\n",
    "    for pred_boxes, gt_boxes in zip(pred_boxes_list, gt_boxes_list):\n",
    "        precision, recall, f1 = calculate_precision_recall_f1(pred_boxes, gt_boxes, iou_threshold)\n",
    "        precision_sum += precision\n",
    "        recall_sum += recall\n",
    "        f1_sum += f1\n",
    "\n",
    "    mean_precision = precision_sum / count if count > 0 else 0\n",
    "    mean_recall = recall_sum / count if count > 0 else 0\n",
    "    mean_f1_score = f1_sum / count if count > 0 else 0\n",
    "    return mean_precision, mean_recall, mean_f1_score\n",
    "\n",
    "mean_precision, mean_recall, mean_f1_score = calculate_map(pred_boxes_list, gt_boxes_list)\n",
    "print(\"mean Average Precision (mAP) : {:.3f}\".format(mean_precision))\n",
    "print(\"mean Average Recall (mAP) : {:.3f}\".format(mean_recall))\n",
    "print(\"mean Average F1 Score (mAF1) : {:.3f}\".format(mean_f1_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
